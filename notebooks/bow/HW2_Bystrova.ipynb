{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "129c4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "from razdel import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4314de5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14412, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('labeled.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b8fb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Для каких стан является эталоном современная с...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>В шапке были ссылки на инфу по текущему фильму...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>УПАД Т! ТАМ НЕЛЬЗЯ СТРОИТЬ! ТЕХНОЛОГИЙ НЕТ! РА...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ебать тебя разносит, шизик.\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Обосрался, сиди обтекай\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Зачем ты пишешь хуйню, дегенерат? Поцелуй в гу...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Бактерия, тебе этого не понять Конечно, я же н...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Почитайте посты у этого автора,может найдете ч...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Уроды!! у нас в семье 3 поколения там родились\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Можем на тебя ещё и модера за безмозглых позва...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment  toxic\n",
       "0                Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1   Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                           Собаке - собачья смерть\\n    1.0\n",
       "3   Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4   тебя не убедил 6-страничный пдф в том, что Скр...    1.0\n",
       "5   Для каких стан является эталоном современная с...    1.0\n",
       "6   В шапке были ссылки на инфу по текущему фильму...    0.0\n",
       "7   УПАД Т! ТАМ НЕЛЬЗЯ СТРОИТЬ! ТЕХНОЛОГИЙ НЕТ! РА...    1.0\n",
       "8                       Ебать тебя разносит, шизик.\\n    1.0\n",
       "9                           Обосрался, сиди обтекай\\n    1.0\n",
       "10  Зачем ты пишешь хуйню, дегенерат? Поцелуй в гу...    1.0\n",
       "11  Бактерия, тебе этого не понять Конечно, я же н...    1.0\n",
       "12  Почитайте посты у этого автора,может найдете ч...    0.0\n",
       "13   Уроды!! у нас в семье 3 поколения там родились\\n    1.0\n",
       "14  Можем на тебя ещё и модера за безмозглых позва...    1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbffbbc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d2477b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60fd46dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train.toxic.values\n",
    "Y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07af34c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# векторизация с дефолтной токенизацией\n",
    "def_vectorizer = CountVectorizer()\n",
    "X1 = def_vectorizer.fit_transform(train.comment)\n",
    "X1_test = def_vectorizer.transform(test.comment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a14a927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11529, 59528), (2883, 59528))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape, X1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc0e5fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral     0.9062    0.8332    0.8682      1901\n",
      "       Toxic     0.7207    0.8330    0.7728       982\n",
      "\n",
      "    accuracy                         0.8332      2883\n",
      "   macro avg     0.8134    0.8331    0.8205      2883\n",
      "weighted avg     0.8430    0.8332    0.8357      2883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# обучение линейного классификатора \n",
    "clf_1 = LogisticRegression(C=0.1, class_weight='balanced',  max_iter=1000)\n",
    "clf_1.fit(X1, Y)\n",
    "report1 = classification_report(Y_test, clf_1.predict(X1_test), target_names=['Neutral', 'Toxic'], digits=4) \n",
    "print(report1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fda673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# векторизация с токенизацией Razdel\n",
    "def razdeltokenizer(text):\n",
    "    tokens = list(tokenize(text))\n",
    "    tokens = [_.text for _ in tokens]\n",
    "    return(tokens)\n",
    "\n",
    "cust_vectorizer = CountVectorizer(tokenizer=razdeltokenizer)\n",
    "X2 = cust_vectorizer.fit_transform(train.comment)\n",
    "X2_test = cust_vectorizer.transform(test.comment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f235383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11529, 60347), (2883, 60347))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2.shape, X2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b78fce47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral     0.9030    0.8375    0.8690      1901\n",
      "       Toxic     0.7241    0.8259    0.7716       982\n",
      "\n",
      "    accuracy                         0.8335      2883\n",
      "   macro avg     0.8136    0.8317    0.8203      2883\n",
      "weighted avg     0.8421    0.8335    0.8358      2883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # обучение линейного классификатора \n",
    "clf_2 = LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000)\n",
    "clf_2.fit(X2, Y)\n",
    "report2 = classification_report(Y_test, clf_2.predict(X2_test), target_names=['Neutral', 'Toxic'], digits=4)\n",
    "print(report2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8188452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mРезультаты LogReg + default tokenizer:\n",
      "\u001b[0m               precision    recall  f1-score   support\n",
      "\n",
      "     Neutral     0.9062    0.8332    0.8682      1901\n",
      "       Toxic     0.7207    0.8330    0.7728       982\n",
      "\n",
      "    accuracy                         0.8332      2883\n",
      "   macro avg     0.8134    0.8331    0.8205      2883\n",
      "weighted avg     0.8430    0.8332    0.8357      2883\n",
      "\n",
      "\u001b[1mРезультаты LogReg + razdel tokenizer:\n",
      "\u001b[0m               precision    recall  f1-score   support\n",
      "\n",
      "     Neutral     0.9030    0.8375    0.8690      1901\n",
      "       Toxic     0.7241    0.8259    0.7716       982\n",
      "\n",
      "    accuracy                         0.8335      2883\n",
      "   macro avg     0.8136    0.8317    0.8203      2883\n",
      "weighted avg     0.8421    0.8335    0.8358      2883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1m\" + \"Результаты LogReg + default tokenizer:\\n\" + \"\\033[0m\", report1)\n",
    "\n",
    "print(\"\\033[1m\" + \"Результаты LogReg + razdel tokenizer:\\n\" + \"\\033[0m\", report2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcaf217",
   "metadata": {},
   "source": [
    "*__Выводы__*: Увеличив итерацию, стала заметна разница. Классификатор с токенизатором Razdel показал результаты лучше (F-мера **+0,003**, Accuracy **+0,02**, Точность **+0,01**, взвешенная полнота  **+0,01**). Пусть и не значительно, зато стабильно по всем показателям.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c896c",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd27a3",
   "metadata": {},
   "source": [
    "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. \n",
    "Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5b50abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    я     ты      и  только     не     он\n",
      "я и ты          0.032  0.133  0.074   0.000  0.000  0.000\n",
      "ты и я          0.032  0.133  0.074   0.000  0.000  0.000\n",
      "я я и только я  0.058  0.000  0.044   0.080  0.000  0.000\n",
      "только не я     0.032  0.000  0.000   0.133  0.233  0.000\n",
      "он              0.000  0.000  0.000   0.000  0.000  0.699\n"
     ]
    }
   ],
   "source": [
    "lines = ['я и ты', 'ты и я', 'я я и только я', 'только не я', 'он']\n",
    "raws = ['я', 'ты', 'и', 'только', 'не', 'он']\n",
    "\n",
    "# токенизируем каждое предложение\n",
    "data = [razdeltokenizer(d) for d in lines]\n",
    "\n",
    "\n",
    "def calculate_tf_idf(docs_tokenized, vocab):\n",
    "    N = len(docs_tokenized)\n",
    "    V = len(vocab)\n",
    "    result = np.zeros((N, V))    \n",
    "    for i in range(0, N):\n",
    "        doc = docs_tokenized[i]\n",
    "        for w in doc:\n",
    "            j = vocab.index(w)\n",
    "            tf = doc.count(w)/len(doc) # посчитали TF\n",
    "            df = 0\n",
    "          \n",
    "            for d in docs_tokenized:\n",
    "                if w in d:\n",
    "                    df += 1\n",
    "            idf = np.log10(N/df)        #посчитали IDF (логарифм)\n",
    "            tfidf = tf * idf\n",
    "            result[i, j] = round(tfidf, 3)\n",
    "            \n",
    "    return result\n",
    "                \n",
    "result = pd.DataFrame(calculate_tf_idf(data, raws), index =  lines, columns = raws)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 3 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к классификаторам:   \n",
    "а) один должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62112e5f",
   "metadata": {},
   "source": [
    "### Модель №1. Логистическая регрессия + TF-idf Vetorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d44470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "745bd58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\eyer8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\") \n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff78494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, tokenizer=razdeltokenizer, stop_words=russian_stopwords, min_df=4, max_df=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90311fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34878fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11529, 8743), (2883, 8743))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73add3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.89      0.84      0.86      1901\n",
      "       Toxic       0.72      0.79      0.75       982\n",
      "\n",
      "    accuracy                           0.82      2883\n",
      "   macro avg       0.80      0.81      0.81      2883\n",
      "weighted avg       0.83      0.82      0.82      2883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lg_classifier = LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000)\n",
    "lg_classifier.fit(X, Y)\n",
    "\n",
    "\n",
    "report = classification_report(Y_test, lg_classifier.predict(X_test), target_names=['Neutral', 'Toxic'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3b70ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_classifier.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4772f81",
   "metadata": {},
   "source": [
    "### Модель №2. Наивный байесовский классификатор + Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e204d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(lowercase=True, tokenizer=razdeltokenizer, stop_words=russian_stopwords, min_df=3, max_df=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1bd478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_v2 = vectorizer.fit_transform(train.comment)\n",
    "X_test_v2 = vectorizer.transform(test.comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d5f1a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11529, 12448), (2883, 12448))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_v2.shape, X_test_v2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f8f36204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Neutral       0.87      0.93      0.90      1901\n",
      "       Toxic       0.84      0.73      0.78       982\n",
      "\n",
      "    accuracy                           0.86      2883\n",
      "   macro avg       0.85      0.83      0.84      2883\n",
      "weighted avg       0.86      0.86      0.86      2883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB_classifier = MultinomialNB()\n",
    "NB_classifier.fit(X_v2, Y)\n",
    "\n",
    "report = classification_report(Y_test, NB_classifier.predict(X_test_v2), target_names=['Neutral', 'Toxic'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b9cebcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.72941821e-01 9.99922587e-01 4.80024981e-07 ... 7.61772164e-02\n",
      " 9.87880026e-01 7.78256343e-01]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNB_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_v2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(NB_classifier.predict_proba(X_test_v2)[:, 1])[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "### *Задание 4 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов LogisticRegression, Decision Trees, Naive Bayes, Random Forest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f86878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15af4e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
